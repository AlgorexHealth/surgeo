{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pathlib\n",
    "import urllib.request\n",
    "import tempfile\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background (links good as of 2019-12-10)\n",
    "\n",
    "<h2 style=\"color: red;\">This takes a fair amount of RAM and download time</h2>\n",
    "\n",
    "This script fetches ~50 .sf1 state and territory zip files from the census server at the following location:\n",
    "\n",
    "* https://www2.census.gov/census_2010/04-Summary_File_1/\n",
    "\n",
    "These each of these zip files contains (among other things) a geographic file and a population file containing.\n",
    "\n",
    "The fixed-width geo file is useful because it ties a  \"Logical Record\" to ZCTA codes. The CSV population file is useful because it contains the actual data we need for the logical records.\n",
    "\n",
    "Specifically, we are pulling our data from population table 9 (\"P9\" ... see Summary File 1 documentation page  184).\n",
    "\n",
    "    P5. HISPANIC OR LATINO ORIGIN BY RACE Universe: Total population (17)\n",
    "\n",
    "The data for this table is as follows:\n",
    "\n",
    "    P5 data:\n",
    "        Total:\n",
    "            Not Hispanic or Latino:\n",
    "                White alone\n",
    "                Black or African American alone\n",
    "                American Indian and Alaska Native alone\n",
    "                Asian alone\n",
    "                Native Hawaiian and Other Pacific Islander alone \n",
    "                Some Other Race alone\n",
    "                Two or More Races\n",
    "            Hispanic or Latino:\n",
    "                White alone\n",
    "                Black or African American alone \n",
    "                American Indian and Alaska Native alone\n",
    "                Asian alone\n",
    "                Native Hawaiian and Other Pacific Islander alone \n",
    "                Some Other Race alone\n",
    "                Two or More Races\n",
    "\n",
    "## Notes:\n",
    "* Geo table must be filtered by summary level == 871 (State-5-Digit ZIP Code Tabulation Area) so that it is limited to ZCTA records.\n",
    "* The cut down geo table is joined to the population table using the LOGRECNO (Log Record Number)\n",
    "* All Hispanic groups are condense to a single group to make consistent with surname data\n",
    "* Asian and API are combined to make consistent with surname data\n",
    "* \"Some Other Race\" is apporitoned abong the groups.\n",
    "\n",
    "For more details, the technical documentation for Summary File 1 can be found here:\n",
    "* https://www.census.gov/prod/cen2010/doc/sf1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the start/stop indices for the fixed width geo file.\n",
    "# It allows them to be easily converted to dataframes.\n",
    "GEO_MAP_2010 = {\n",
    "    'FILEID'  : (1  , 7  ),\n",
    "    'STUSAB'  : (7  , 9  ),\n",
    "    'SUMLEV'  : (9  , 12 ),\n",
    "    'GEOCOMP' : (12 , 14 ),\n",
    "    'CHARITER': (14 , 17 ),\n",
    "    'CIFSN'   : (17 , 19 ),\n",
    "    'LOGRECNO': (19 , 26 ),\n",
    "    'REGION'  : (26 , 27 ),\n",
    "    'DIVISION': (27 , 28 ),\n",
    "    'STATE'   : (28 , 30 ),\n",
    "    'COUNTY'  : (30 , 33 ),\n",
    "    'COUNTYCC': (33 , 35 ),\n",
    "    'COUNTYSC': (35 , 37 ),\n",
    "    'COUSUB'  : (37 , 42 ),\n",
    "    'COUSUBCC': (42 , 44 ),\n",
    "    'COUSUBSC': (44 , 46 ),\n",
    "    'PLACE'   : (46 , 51 ),\n",
    "    'PLACECC' : (51 , 53 ),\n",
    "    'PLACESC' : (53 , 55 ),\n",
    "    'TRACT'   : (55 , 61 ),\n",
    "    'BLKGRP'  : (61 , 62 ),\n",
    "    'BLOCK'   : (62 , 66 ),\n",
    "    'IUC'     : (66 , 68 ),\n",
    "    'CONCIT'  : (68 , 73 ),\n",
    "    'CONCITCC': (73 , 75 ),\n",
    "    'CONCITSC': (75 , 77 ),\n",
    "    'AIANHH'  : (77 , 81 ),\n",
    "    'AIANHHFP': (81 , 86 ),\n",
    "    'AIANHHCC': (86 , 88 ),\n",
    "    'AIHHTLI' : (88 , 89 ),\n",
    "    'AITSCE'  : (89 , 92 ),\n",
    "    'AITS'    : (92 , 97 ),\n",
    "    'AITSCC'  : (97 , 99 ),\n",
    "    'TTRACT'  : (99 , 105),\n",
    "    'TBLKGRP' : (105, 106),\n",
    "    'ANRC'    : (106, 111),\n",
    "    'ANRCCC'  : (111, 113),\n",
    "    'CBSA'    : (113, 118),\n",
    "    'CBSASC'  : (118, 120),\n",
    "    'METDIV'  : (120, 125),\n",
    "    'CSA'     : (125, 128),\n",
    "    'NECTA'   : (128, 133),\n",
    "    'NECTASC' : (133, 135),\n",
    "    'NECTADIV': (135, 140),\n",
    "    'CNECTA'  : (140, 143),\n",
    "    'CBSAPCI' : (143, 144),\n",
    "    'NECTAPCI': (144, 145),\n",
    "    'UA'      : (145, 150),\n",
    "    'UASC'    : (150, 152),\n",
    "    'UATYPE'  : (152, 153),\n",
    "    'UR'      : (153, 154),\n",
    "    'CD'      : (154, 156),\n",
    "    'SLDU'    : (156, 159),\n",
    "    'SLDL'    : (159, 162),\n",
    "    'VTD'     : (162, 168),\n",
    "    'VTDI'    : (168, 169),\n",
    "    'RESERVE2': (169, 172),\n",
    "    'ZCTA5'   : (172, 177),\n",
    "    'SUBMCD'  : (177, 182),\n",
    "    'SUBMCDCC': (182, 184),\n",
    "    'SDELM'   : (184, 189),\n",
    "    'SDSEC'   : (189, 194),\n",
    "    'SDUNI'   : (194, 199),\n",
    "    'AREALAND': (119, 213),\n",
    "    'AREAWATR': (213, 227),\n",
    "    'NAME'    : (227, 317),\n",
    "    'FUNCSTAT': (317, 318),\n",
    "    'GCUNI'   : (318, 319),\n",
    "    'POP100'  : (319, 328),\n",
    "    'HU100'   : (328, 337),\n",
    "    'INTPTLAT': (337, 348),\n",
    "    'INTPTLON': (348, 360),\n",
    "    'LSADC'   : (360, 362),\n",
    "    'PARTFLAG': (362, 363),\n",
    "    'RESERVE3': (363, 369),\n",
    "    'UGA'     : (369, 374),\n",
    "    'STATENS' : (374, 382),\n",
    "    'COUNTYNS': (382, 390),\n",
    "    'COUSUBNS': (390, 398),\n",
    "    'PLACENS' : (398, 406),\n",
    "    'CONCITNS': (406, 414),\n",
    "    'AIANHHNS': (414, 422),\n",
    "    'AITSNS'  : (422, 430),\n",
    "    'ANRCNS'  : (430, 438),\n",
    "    'SUBMCDNS': (438, 446),\n",
    "    'CD113'   : (446, 448),\n",
    "    'CD114'   : (448, 450),\n",
    "    'CD115'   : (450, 452),\n",
    "    'SLDU2'   : (452, 455),\n",
    "    'SLDU3'   : (455, 458),\n",
    "    'SLDU4'   : (458, 461),\n",
    "    'SLDL2'   : (461, 464),\n",
    "    'SLDL3'   : (464, 467),\n",
    "    'SLDL4'   : (467, 470),\n",
    "    'AIANHHSC': (470, 472),\n",
    "    'CSASC'   : (472, 476),\n",
    "    'CNECTASC': (474, 477),\n",
    "    'MEMI'    : (476, 478),\n",
    "    'NMEMI'   : (477, 478),\n",
    "    'PUMA'    : (478, 483),\n",
    "    'RESERVED': (483, 501),\n",
    "}\n",
    "\n",
    "# Our zip downloads have URLs that can be recreated with state/arrevs.\n",
    "STATES = {\n",
    "    'AL': 'Alabama',\n",
    "    'AK': 'Alaska',\n",
    "    'AZ': 'Arizona',\n",
    "    'AR': 'Arkansas',\n",
    "    'CA': 'California',\n",
    "    'CO': 'Colorado',\n",
    "    'CT': 'Connecticut',\n",
    "    'DE': 'Delaware',\n",
    "    'DC': 'District_of_Columbia',\n",
    "    'FL': 'Florida',\n",
    "    'GA': 'Georgia',\n",
    "    'HI': 'Hawaii',\n",
    "    'ID': 'Idaho',\n",
    "    'IL': 'Illinois',\n",
    "    'IN': 'Indiana',\n",
    "    'IA': 'Iowa',\n",
    "    'KS': 'Kansas',\n",
    "    'KY': 'Kentucky',\n",
    "    'LA': 'Louisiana',\n",
    "    'ME': 'Maine',\n",
    "    'MD': 'Maryland',\n",
    "    'MA': 'Massachusetts',\n",
    "    'MI': 'Michigan',\n",
    "    'MN': 'Minnesota',\n",
    "    'MS': 'Mississippi',\n",
    "    'MO': 'Missouri',\n",
    "    'MT': 'Montana',\n",
    "    'NE': 'Nebraska',\n",
    "    'NV': 'Nevada',\n",
    "    'NH': 'New_Hampshire',\n",
    "    'NJ': 'New_Jersey',\n",
    "    'NM': 'New_Mexico',\n",
    "    'NY': 'New_York',\n",
    "    'NC': 'North_Carolina',\n",
    "    'ND': 'North_Dakota',\n",
    "    'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon',\n",
    "    'PA': 'Pennsylvania',\n",
    "    'PR': 'Puerto_Rico',\n",
    "    'RI': 'Rhode_Island',\n",
    "    'SC': 'South_Carolina',\n",
    "    'SD': 'South_Dakota',\n",
    "    'TN': 'Tennessee',\n",
    "    'TX': 'Texas',\n",
    "    'UT': 'Utah',\n",
    "    'VT': 'Vermont',\n",
    "    'VA': 'Virginia',\n",
    "    'WA': 'Washington',\n",
    "    'WV': 'West_Virginia',\n",
    "    'WI': 'Wisconsin',\n",
    "    'WY': 'Wyoming',    \n",
    "}\n",
    "\n",
    "# This is the template for the URLs\n",
    "URL_TEMPLATE_ZIP = 'https://www2.census.gov/census_2010/04-Summary_File_1/{state}/{state_abbrev}2010.sf1.zip'\n",
    "\n",
    "TEMP_DIR = pathlib.Path(tempfile.gettempdir()) / 'surgeo_temp'\n",
    "TEMP_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# This creates a URL with each and every state in the STATES dictioanry\n",
    "urls = [\n",
    "    URL_TEMPLATE_ZIP.format(state_abbrev=code.lower(), state=name)\n",
    "    for code, name\n",
    "    in STATES.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_data(url, retries):\n",
    "    '''Helper that attempts to get file a number of times'''\n",
    "    tries = 0\n",
    "    while True:\n",
    "        try:\n",
    "            with urllib.request.urlopen(url) as r:\n",
    "                data = r.read()\n",
    "                return data\n",
    "        except Exception:\n",
    "            tries += 1\n",
    "            if tries >= retries:\n",
    "                raise\n",
    "        print('Retrying {url}...'.format(url))\n",
    "\n",
    "def dl_file(url, file_path):\n",
    "    '''Helper func: downloads zip from URL and stores it in local folder'''\n",
    "    # If it exsits do nothing\n",
    "    if file_path.exists():\n",
    "        print('{} is already present. Processing ...'.format(file_path))\n",
    "        pass\n",
    "    # Otherwise download file to dir\n",
    "    else:\n",
    "    # Open request\n",
    "        data = request_data(url, 3)\n",
    "        file_path.touch()\n",
    "        file_path.write_bytes(data)\n",
    "\n",
    "def make_geo_df(file_path):\n",
    "    '''Helper func: takes zip and creates a geographic file from data'''\n",
    "    # Read zip data\n",
    "    with zipfile.ZipFile(file_path) as zf:\n",
    "        # Filter out everything except the ZipInfo (geo) for csv we want\n",
    "        target = zf.filelist[0]\n",
    "        # Read that CSV into BytesIO object\n",
    "        geo_data = io.BytesIO(zf.read(target))\n",
    "        # Read fixed-width file into dataframe\n",
    "        geo_df = pd.read_fwf(\n",
    "            geo_data, \n",
    "            header=None,\n",
    "            # Use the GEO MAP but subtract from column start/stop\n",
    "            colspecs=[\n",
    "                (tuple_[0] - 1, tuple_[1] - 1)\n",
    "                for tuple_\n",
    "                in GEO_MAP_2010.values()\n",
    "            ],\n",
    "            dtype=str\n",
    "        )\n",
    "    # Give names to columns\n",
    "    geo_df.columns = tuple(GEO_MAP_2010.keys())\n",
    "    # Filter out all records that are not related to ZCTAs only\n",
    "    # e.g. get rid of census block data\n",
    "    geo_df = geo_df.loc[geo_df.SUMLEV == '871']\n",
    "    # Keep the STUSAB (state), LOGRECONO (join key), and ZCTA5 (zip code proxy)\n",
    "    geo_df = geo_df[['STUSAB', 'LOGRECNO', 'ZCTA5']]#.dropna(subset=['ZCTA5'])\n",
    "    return geo_df\n",
    "\n",
    "def make_pop_df(file_path):\n",
    "    '''Helper func: Takes a zip and creates population df'''\n",
    "    # Read zip data\n",
    "    with zipfile.ZipFile(file_path) as zf:\n",
    "        # Filter out everything except the ZipInfo for csv we want\n",
    "        # This contains Table P5\n",
    "        target = zf.filelist[3]\n",
    "        # Read that CSV into BytesIO object\n",
    "        pop_data = io.BytesIO(zf.read(target))\n",
    "        pop_df = pd.read_csv(\n",
    "            pop_data, \n",
    "            header=None,\n",
    "            dtype=str\n",
    "        )\n",
    "        # Keep only a subset of columns and renames them\n",
    "        pop_df = pop_df[[1, 4, 18, 19, 20, 21, 22, 23, 24, 25]]\n",
    "        pop_df.columns = [\n",
    "            'STUSAB',\n",
    "            'LOGRECNO',\n",
    "            'white',\n",
    "            'black',\n",
    "            'native',\n",
    "            'asian',\n",
    "            'pi',\n",
    "            'other',\n",
    "            'multiple',\n",
    "            'hispanic',\n",
    "        ]\n",
    "        return pop_df\n",
    "\n",
    "def merge_frames(geo_df, pop_df):\n",
    "    '''Merges our GEO and POP frames'''\n",
    "    # Merges common STUSAB and LOGRECNO fields\n",
    "    merged = geo_df.merge(pop_df)\n",
    "    # Rename zctq5\n",
    "    merged = merged.rename(columns={'ZCTA5': 'zcta5'})\n",
    "    # Set index to ZCTA5 and sort\n",
    "    merged = merged.set_index('zcta5')\n",
    "    merged = merged.sort_index()\n",
    "    return merged\n",
    "    \n",
    "def create_df(url, temp_dir):\n",
    "    '''Main function to download, join, and clean data for single state'''\n",
    "    print(url)\n",
    "    file_name = url.rpartition('/')[2]\n",
    "    file_path = temp_dir / file_name \n",
    "    # Download\n",
    "    data   = dl_file(url, file_path)\n",
    "    # Make dfs\n",
    "    geo_df = make_geo_df(file_path)\n",
    "    pop_df = make_pop_df(file_path)\n",
    "    # Join DFs, sort, trip, and process\n",
    "    df     = merge_frames(geo_df, pop_df)\n",
    "    df = df.iloc[:, 2:]\n",
    "    df = df.astype(np.float64)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download.\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Alabama/al2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\al2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Alaska/ak2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\ak2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Arizona/az2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\az2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Arkansas/ar2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\ar2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/California/ca2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\ca2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Colorado/co2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\co2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Connecticut/ct2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\ct2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Delaware/de2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\de2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/District_of_Columbia/dc2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\dc2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Florida/fl2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\fl2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Georgia/ga2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\ga2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Hawaii/hi2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\hi2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Idaho/id2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\id2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Illinois/il2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\il2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Indiana/in2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\in2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Iowa/ia2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\ia2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Kansas/ks2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\ks2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Kentucky/ky2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\ky2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Louisiana/la2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\la2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Maine/me2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\me2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Maryland/md2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\md2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Massachusetts/ma2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\ma2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Michigan/mi2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\mi2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Minnesota/mn2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\mn2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Mississippi/ms2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\ms2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Missouri/mo2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\mo2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Montana/mt2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\mt2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Nebraska/ne2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\ne2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Nevada/nv2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\nv2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/New_Hampshire/nh2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\nh2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/New_Jersey/nj2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\nj2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/New_Mexico/nm2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\nm2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/New_York/ny2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\ny2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/North_Carolina/nc2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\nc2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/North_Dakota/nd2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\nd2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Ohio/oh2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\oh2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Oklahoma/ok2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\ok2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Oregon/or2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\or2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Pennsylvania/pa2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\pa2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Puerto_Rico/pr2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\pr2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Rhode_Island/ri2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\ri2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/South_Carolina/sc2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\sc2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/South_Dakota/sd2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\sd2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Tennessee/tn2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\tn2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Texas/tx2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\tx2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Utah/ut2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\ut2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Vermont/vt2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\vt2010.sf1.zip is already present. Processing ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www2.census.gov/census_2010/04-Summary_File_1/Virginia/va2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\va2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Washington/wa2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\wa2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/West_Virginia/wv2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\wv2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Wisconsin/wi2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\wi2010.sf1.zip is already present. Processing ...\n",
      "https://www2.census.gov/census_2010/04-Summary_File_1/Wyoming/wy2010.sf1.zip\n",
      "C:\\Users\\theon\\AppData\\Local\\Temp\\surgeo_temp\\wy2010.sf1.zip is already present. Processing ...\n",
      "Download complete.\n"
     ]
    }
   ],
   "source": [
    "print('Starting download.')\n",
    "\n",
    "# Create a dataframe for each URL and store in list\n",
    "data = [\n",
    "    create_df(url, TEMP_DIR)\n",
    "    for url\n",
    "    in urls\n",
    "]\n",
    "\n",
    "print('Download complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all data into single dataframe and sort index\n",
    "df = pd.concat(data)\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "      <th>native</th>\n",
       "      <th>asian</th>\n",
       "      <th>pi</th>\n",
       "      <th>other</th>\n",
       "      <th>multiple</th>\n",
       "      <th>hispanic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zcta5</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69201</th>\n",
       "      <td>3291.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69201</th>\n",
       "      <td>36.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        white  black  native  asian   pi  other  multiple  hispanic\n",
       "zcta5                                                              \n",
       "69201  3291.0    4.0   265.0   20.0  0.0    0.0      97.0      61.0\n",
       "69201    36.0    2.0   196.0    5.0  0.0    0.0      19.0       9.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check a ZCTA that crosses state lines\n",
    "df.loc['69201']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "      <th>native</th>\n",
       "      <th>asian</th>\n",
       "      <th>pi</th>\n",
       "      <th>other</th>\n",
       "      <th>multiple</th>\n",
       "      <th>hispanic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zcta5</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00601</th>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18486.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00602</th>\n",
       "      <td>216.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>41265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00603</th>\n",
       "      <td>628.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>53877.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00606</th>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6575.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00610</th>\n",
       "      <td>187.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28789.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       white  black  native  asian   pi  other  multiple  hispanic\n",
       "zcta5                                                             \n",
       "00601   80.0    2.0     1.0    1.0  0.0    0.0       0.0   18486.0\n",
       "00602  216.0   13.0     0.0   15.0  0.0    4.0       7.0   41265.0\n",
       "00603  628.0  101.0     2.0   48.0  2.0    9.0      22.0   53877.0\n",
       "00606   32.0    3.0     0.0    3.0  1.0    0.0       1.0    6575.0\n",
       "00610  187.0   22.0     0.0    8.0  0.0    5.0       5.0   28789.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/theonaunheim/surgeo/issues/10\n",
    "# Certain zctas cross state lines and must be added together.\n",
    "df = df.groupby(df.index).apply(sum)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "white       3327.0\n",
       "black          6.0\n",
       "native       461.0\n",
       "asian         25.0\n",
       "pi             0.0\n",
       "other          0.0\n",
       "multiple     116.0\n",
       "hispanic      70.0\n",
       "Name: 69201, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recheck zip that crosses state lines\n",
    "df.loc['69201']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zcta5\n",
       "00601    18570.0\n",
       "00602    41520.0\n",
       "00603    54689.0\n",
       "00606     6615.0\n",
       "00610    29016.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store column totals\n",
    "totals = df.sum(axis=1)\n",
    "totals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zcta5\n",
       "00601    0.0\n",
       "00602    4.0\n",
       "00603    9.0\n",
       "00606    0.0\n",
       "00610    5.0\n",
       "Name: other, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store some other race so it can be divvyed up among other groups\n",
    "other = df['other']\n",
    "other.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "      <th>native</th>\n",
       "      <th>asian</th>\n",
       "      <th>pi</th>\n",
       "      <th>other</th>\n",
       "      <th>multiple</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>api</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zcta5</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00601</th>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18486.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00602</th>\n",
       "      <td>216.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>41265.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00603</th>\n",
       "      <td>628.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>53877.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00606</th>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6575.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00610</th>\n",
       "      <td>187.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28789.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       white  black  native  asian   pi  other  multiple  hispanic   api\n",
       "zcta5                                                                   \n",
       "00601   80.0    2.0     1.0    1.0  0.0    0.0       0.0   18486.0   1.0\n",
       "00602  216.0   13.0     0.0   15.0  0.0    4.0       7.0   41265.0  15.0\n",
       "00603  628.0  101.0     2.0   48.0  2.0    9.0      22.0   53877.0  50.0\n",
       "00606   32.0    3.0     0.0    3.0  1.0    0.0       1.0    6575.0   4.0\n",
       "00610  187.0   22.0     0.0    8.0  0.0    5.0       5.0   28789.0   8.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Asian or Pacific Islander (this is what surname uses)\n",
    "df['api'] = df['asian'] + df['pi']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "      <th>native</th>\n",
       "      <th>multiple</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>api</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zcta5</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00601</th>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18486.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00602</th>\n",
       "      <td>216.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>41265.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00603</th>\n",
       "      <td>628.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>53877.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00606</th>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6575.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00610</th>\n",
       "      <td>187.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28789.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       white  black  native  multiple  hispanic   api\n",
       "zcta5                                                \n",
       "00601   80.0    2.0     1.0       0.0   18486.0   1.0\n",
       "00602  216.0   13.0     0.0       7.0   41265.0  15.0\n",
       "00603  628.0  101.0     2.0      22.0   53877.0  50.0\n",
       "00606   32.0    3.0     0.0       1.0    6575.0   4.0\n",
       "00610  187.0   22.0     0.0       5.0   28789.0   8.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns we will no longer use\n",
    "df = df.drop(columns=['other', 'asian', 'pi'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "      <th>native</th>\n",
       "      <th>multiple</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>api</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zcta5</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00601</th>\n",
       "      <td>0.004308</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.995477</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00602</th>\n",
       "      <td>0.005202</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.993858</td>\n",
       "      <td>0.000361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00603</th>\n",
       "      <td>0.011483</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.985152</td>\n",
       "      <td>0.000914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00606</th>\n",
       "      <td>0.004837</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.993953</td>\n",
       "      <td>0.000605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00610</th>\n",
       "      <td>0.006445</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.992177</td>\n",
       "      <td>0.000276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          white     black    native  multiple  hispanic       api\n",
       "zcta5                                                            \n",
       "00601  0.004308  0.000108  0.000054  0.000000  0.995477  0.000054\n",
       "00602  0.005202  0.000313  0.000000  0.000169  0.993858  0.000361\n",
       "00603  0.011483  0.001847  0.000037  0.000402  0.985152  0.000914\n",
       "00606  0.004837  0.000454  0.000000  0.000151  0.993953  0.000605\n",
       "00610  0.006445  0.000758  0.000000  0.000172  0.992177  0.000276"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now determine what percent of the row each items makes up.\n",
    "percentages = df.divide(totals, axis='rows')\n",
    "percentages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "      <th>native</th>\n",
       "      <th>multiple</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>api</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zcta5</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00601</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00602</th>\n",
       "      <td>0.020809</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>3.975434</td>\n",
       "      <td>0.001445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00603</th>\n",
       "      <td>0.103348</td>\n",
       "      <td>0.016621</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>8.866372</td>\n",
       "      <td>0.008228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00606</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00610</th>\n",
       "      <td>0.032224</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>4.960884</td>\n",
       "      <td>0.001379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          white     black    native  multiple  hispanic       api\n",
       "zcta5                                                            \n",
       "00601  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "00602  0.020809  0.001252  0.000000  0.000674  3.975434  0.001445\n",
       "00603  0.103348  0.016621  0.000329  0.003620  8.866372  0.008228\n",
       "00606  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "00610  0.032224  0.003791  0.000000  0.000862  4.960884  0.001379"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split up 'other' into the remaining rows based on the percents above\n",
    "apportioned_other = percentages.multiply(other, axis='rows')\n",
    "apportioned_other.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "      <th>native</th>\n",
       "      <th>multiple</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>api</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zcta5</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00601</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18486.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00602</th>\n",
       "      <td>216.020809</td>\n",
       "      <td>13.001252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000674</td>\n",
       "      <td>41268.975434</td>\n",
       "      <td>15.001445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00603</th>\n",
       "      <td>628.103348</td>\n",
       "      <td>101.016621</td>\n",
       "      <td>2.000329</td>\n",
       "      <td>22.003620</td>\n",
       "      <td>53885.866372</td>\n",
       "      <td>50.008228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00606</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6575.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00610</th>\n",
       "      <td>187.032224</td>\n",
       "      <td>22.003791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000862</td>\n",
       "      <td>28793.960884</td>\n",
       "      <td>8.001379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            white       black    native   multiple      hispanic        api\n",
       "zcta5                                                                      \n",
       "00601   80.000000    2.000000  1.000000   0.000000  18486.000000   1.000000\n",
       "00602  216.020809   13.001252  0.000000   7.000674  41268.975434  15.001445\n",
       "00603  628.103348  101.016621  2.000329  22.003620  53885.866372  50.008228\n",
       "00606   32.000000    3.000000  0.000000   1.000000   6575.000000   4.000000\n",
       "00610  187.032224   22.003791  0.000000   5.000862  28793.960884   8.001379"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute 'other' to the remaining groups based on percentage makeup\n",
    "# quasi Iterative proportortional fit / matrix rake over single dimension\n",
    "df += apportioned_other\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconvert to percentage\n",
    "column_totals = df.sum(axis=0)\n",
    "ratio_by_column = df.divide(column_totals, axis='columns').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "ratio_by_column = ratio_by_column[[\n",
    "    'white',\n",
    "    'black',\n",
    "    'api',\n",
    "    'native',\n",
    "    'multiple',\n",
    "    'hispanic'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconvert to percentage\n",
    "row_totals = df.sum(axis=1)\n",
    "ratio_by_row = df.divide(row_totals, axis='index').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "ratio_by_row = ratio_by_row[[\n",
    "    'white',\n",
    "    'black',\n",
    "    'api',\n",
    "    'native',\n",
    "    'multiple',\n",
    "    'hispanic'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write data to module as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = pathlib.Path().cwd()\n",
    "project_directory = current_directory.parents[0]\n",
    "data_directory    = project_directory / 'surgeo' / 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prob zcta given race\n",
    "rbc_path = data_directory / 'prob_zcta_given_race_2010.csv'\n",
    "ratio_by_column.to_csv(rbc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prob race given block zcta\n",
    "rbr_path = data_directory / 'prob_race_given_zcta_2010.csv'\n",
    "ratio_by_row.to_csv(rbr_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up TEMP_DIR\n",
    "\n",
    "If you turn this into comments, you cache the census files locally so you do not have to re-download everything (because the census FTP server drops connections like nobody's business). This comes at the expense of ~10GB disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete files\n",
    "for path in TEMP_DIR.rglob('*')\n",
    "    path.unlink()\n",
    "\n",
    "# Delete dir\n",
    "TEMP_DIR.rmdir()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
